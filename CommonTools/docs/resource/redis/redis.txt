 1.redis基础

  Redis中的值可以是由string（字符串）、hash（哈希）、 list（列表）、set（集合）、zset（有序集合）、Bitmaps（位图）、 HyperLogLog、GEO（地理信息定位）等多种数据结构和算法组成。
  Redis提供了两种持久化方式：RDB和 AOF。http://blog.csdn.net/canot/article/details/52886923
  Redis 集群规范：http://redisdoc.com/topic/cluster-spec.html#redis  HASH_SLOT = CRC16(key) mod 16384
  
  
 redis 全局命令：
        查看所有键 ： keys *  遍历所有的key，时间复杂度O(n),产线环境慎用。
		查看键总数 ： dbsize  直接获取Redis内置的键总数变量，时间复杂度是O(1)。
		判断key是否存在 exists key
		删除key(多个)   del key [key ...]
		设置key过期时间 expire key seconds
		查看key的剩余过期时间  ttl key
		查看key的数据结构类型  type key
		设置值命令 set key value [ex seconds] [px milliseconds] [nx|xx]
               ex seconds：为键设置秒级过期时间。（同 setex命令）
		       px milliseconds：为键设置毫秒级过期时间。
		       nx：键必须不存在，才可以设置成功，用于添加。（同 setnx命令，分布式锁基于redis的实现就是基于setnx命令）
		       xx：与nx相反，键必须存在，才可以设置成功，用于更新。
        批量操作命令：mget mset 批量操作命令可以有效提高开发效率，减少多次网络IO的开销。redis服务端的处理性能已经足够高，网络可能成为性能瓶颈。
	
	
  redis 客户端命令：
     migrate ：MIGRATE host port key destination -db timeout [COPY][REPLACE]  key 原子性地从当前实例传送到目标实例的指定数据库上，一旦传送成功，key保证会出现在目标实例上，而当前实例上的 key 会被删除。
     append ： APPEND key value                                               key已经存在且值为字符串，会把 value 追加到原来值，如果key不存同set命令。
     incr ：   INCR key                                                       key的数值执行原子的加1操作。(java 内部的计数操作是基于cas实现的，会有一定的cpu开销，redis是单线程命令顺序执行，不存在这个问题)
     getset：  GETSET key value                                               和set一样会设置值，同时会返回键原来的值
     randomkey : 随机返回一个key
     scan ：scan采用渐进式遍历的方式来解决keys命令可能带来的阻塞问题。
            scan cursor [match pattern] [count number]
	             cursor是必需参数，cursor是一个游标，第一次遍历从0开始，每一次的scan遍历完都会返回当前游标的值，直到游标值为0表示遍历所有的key结束。
                 match pattern是可选参数，它的作用的是做模式的匹配，这点和keys的模式匹配很像。
                 count number是可选参数，它的作用是表明每次要遍历的键个数，默认值是10，此参数可以适当增大。	    
            
     
  redis key迁移的三种方式：
     move、dump+restore、migrate是Redis发展过程中三种迁移键的方式，其中move命令基本废弃，migrate命令用原子性的方式实现了dump+restore，
     并且支持批量操作，是Redis Cluster实现水平扩容的重要工具。
  
     
  redis架构：Redis使用了单线程架构和I/O多路复用模型来实现高性能的内存数据库服务，所有命令在一个队列里排队等待被执行。
             redis单线程达到每秒万级别的处理能力原因？
	    1.纯内存访问 
	    2.非阻塞I/O，使用epoll作为I/O多路复用技术的实现，自身的事件处理模型将epoll中的连接、读写、关闭都转换为事件，不在网络I/O上浪费过多的时间。
	    3.单线程避免线程切换和资源竞争带来的消耗。
	    
 
  1.redis 数据结构和内部编码 ：Redis存储键值对使用的是hashtable的数据结构（所以get操作时间复杂度是O(1)），但是Redis为每种数据类型都提供了多种内部编码方式，
                               其选择对于使用者来说是透明的，Redis会根据实际情况自动调整。	http://blog.csdn.net/gqtcgq/article/details/50240383
   
   查看一个键的内部编码方式命令 ： object encoding KEY
  
   1.1.String ：
       REDIS_ENCODING_RAW 0     /* Raw representation */    
       REDIS_ENCODING_INT 1     /* Encoded as integer */ 
       REDIS_ENCODING_EMBSTR 8  /* Embedded sds string encoding */  	       
       
	  RAW编码方式使用简单动态字符串来保存字符串对象，INT编码方式以整数保存字符串数据且仅能用long类型值表达的字符串。
       正常情况下String类型的键值是以RAW存储的，当键值内容可以用一个64位有符号整数表示时，Redis会将键值转换成long类型来存储，这比使用存储字符串更加节省空间。
       当redisObject中的LRU值没有意义的时候(实例没有设置maxmemory限制或者maxmemory-policy设置的淘汰算法中不计算LRU值时)， 0-10000之间的OBJ_ENCODING_INT编码的字符串对象将进行共享，
       以节省存储空间。
       
       OBJ_ENCODING_EMBSTR_SIZE_LIMIT 39
       
       tips：Redis 3.0版本开始字符串引入了EMBSTR编码方式，长度小于OBJ_ENCODING_EMBSTR_SIZE_LIMIT的字符串将以EMBSTR方式存储。
	     EMBSTR方式的意思是 embedded string ，字符串的空间将会和redisObject对象的空间一起分配，两者在同一个内存块中。
   
   1.2 Hash(散列类型): 
	REDIS_ENCODING_HT 2      /* Encoded as hashtable */   
	REDIS_ENCODING_ZIPMAP 3 (已经废弃) /* Encoded as zipmap */  
   
	hash-max-ziplist-entries 512
	hash-max-ziplist-value 64		
	
	当散列类型键的字段个数少于hash-max-ziplist-entries，且每个字段名和字段值的长度都小于hash-max-ziplist-value时（字节），Redis就会使用zipList来存储该键，
	否则就会使用hashtable。hashtable可以实现O(1)时间复杂度的赋值取值等操作，其字段和字段值都是使用redisObject存储的。zipList是一种紧凑的编码格式，
	它牺牲了部分读取性能以换取极高的空间利用率，适合在元素较少时使用。
  
  1.3 List(列表类型) 
       REDIS_ENCODING_LINKEDLIST 4 /* Encoded as regular linked list */ 
       REDIS_ENCODING_ZIPLIST 5 /* Encoded as ziplist */ 
  
       list-max-ziplist-entries 512
       list-max-ziplist-value 64
       
       当散列类型键的字段个数少于st-max-ziplist-entries，且每个字段名和字段值的长度都小于hash-max-list-max-ziplist-value时（64字节），Redis就会使用zipList来存储该键，
       否则就会使用linkedlist。linkedlist编码方式即双向链表，链表中的每个元素是用redisObject方式存储的。ziplist是一种紧凑的编码格式，它牺牲了部分读取性能以换取极高的空间利用率，适合在元素较少时使用。
  
  1.4 Set(集合) 
     REDIS_ENCODING_INTSET 6  /* Encoded as intset */   
     REDIS_ENCODING_HT 2      /* Encoded as hashtable */ 
  
     set-max-intset-entries 512
     
     当集合中的所有元素都是整数且元素的个数小于配置文件中的set-max-intset-entries（默认是512）时Redis会使用intset编码存储该集合，否则会使用hashtable来存储。
     insert编码以有序的方式存储元素（所以使用smembers命令获得的结果是有序的），节省空间，可以使用二分算法query，但add del元素操作都需要调整后面元素的内存位置，所以当集合中的元素太多时性能较差。
     
     tips:在Redis 3.2版本之前，一般的链表使用linkedlist编码，之后所有的链表都是用quicklist编码。两者都是使用基本的双端链表数据结构，区别是quicklist每个节点的值都是使用ziplist进行存储的，更加节省空间。
     
  1.5 Zset(有序集合类型): 
      REDIS_ENCODING_LINKEDLIST 4 /* Encoded as regular linked list */ 
      REDIS_ENCODING_SKIPLIST 7  /* Encoded as skiplist */   
    
      zset-max-ziplist-entries  128  
      zset-max-ziplist-value  64  

    当集合中的所有元素都是整数且元素的个数小于配置文件中的zset-max-intset-entries（默认是128）时Redis会使用ziplist编码存储该集合，否则会使用skiplist来存储。
    skiplist用来存储元素的分数及其到元素值的映射以实现排序的功能。Redis对跳跃列表的实现进行了几点修改，其中包括允许跳跃列表中的元素（即分数）相同，
    还有为跳跃列表每个节点增加了指向前一个元素的指针以实现倒序查找。
    
    
  总结：（空间换时间还是时间换空间？取决于自身实际业务）
      1.链表(List),哈希(Hash),有序集合(Sorted Set)在成员较少，成员值较小的时候都会采用压缩列表(ZIPLIST)编码方式进行存储。压缩列表简单来说就是一系列连续的内存数据块，其内存利用率很高，但增删改查效率较低，所以只会在成员较少，值较小的情况下使用。
      2.在Redis 3.2版本之后所有的链表都是用quicklist编码。quicklist也是基于双端链表数据结构，但每个节点的值都是使用ziplist进行存储的，更加节省空间。
      3.在Redis 3.0版本之后引入字符串引入了EMBSTR编码方式，通过key，value共享空间减少内存使用。
	
  2.redis客户端服务端的通信协议
    Redis制定了RESP（Redis Serialization Protocol，Redis序列化协议）实现客户端与服务端的正常交互，这种协议简单高效，既能够被机器解析，又容易被我们识别。
    
    2.1 RESP的规定一条命令的格式如下，CRLF代表"\r\n"。
        *<参数数量> CRLF
	  N
        $<参数1的字节数量> CRLF
         <参数1> CRLF
         ...
        $<参数N的字节数量> CRLF
         <参数N>
	 
    2.2 以 set hello world 命令为例：
       
          *3表示命令参数个数是3个
	  $3/$5/$5 表示每个参数的长度为3/5/5个字节
	  \r\n 表示换行

        *3\r\n$3\r\nSET\r\n$5\r\nhello\r\n$5\r\nworld\r\n
   
    2.3 RESP返回结果格式
         5种返回格式的编码：
            状态回复：在RESP中第一个字节为"+"。      set命令
			错误回复：在RESP中第一个字节为"-"。      ser一个错误的命令
			整数回复：在RESP中第一个字节为"："。     incr命令
			字符串回复：在RESP中第一个字节为"$"。    get命令
			多条字符串回复：在RESP中第一个字节为"*"。mget命令
	    
	    redis-cli只能看到最终的执行结果，因为其本身就是按照RESP进行结果解析的，所以看不到中间结果。如果想看到中间结果可以使用nc命令、telnet命令、甚至写一个socket程序进行模拟。
  
  3.redis请求路由：moved转向 ask转向。
         moved转向：通常在集群模式下，Redis接收任何key相关命令时首先计算键对应的slot，再根据slot找出所对应的node节点，如果node节点是自身，则处理key命令；
	            否则回复MOVED重定向错误，通知客户端请求正确的node节点。使用redis-cli命令时，可以加入-c参数支持自动重定向，这个过程是在redis-cli
                    内部维护，实质上是client端接到MOVED信息之后再次发起请求，因为节点对于不属于它的键命令只回复重定向响应，并不负责转发。
	
	     ask转向：出现在在线迁移solt和数据的过程中。会出现一部数据在源节点，一部分数据在目标节点的情况，这时候我们需要通过ask转向目前节点获取剩下的数据。
	 
	     tips：1.二者有着本质的区别，ASK重定向说明集群正在进行slot数据迁移，客户端无法知道什么时候迁移完成，因此只能是临时性的重定向，客户端不会更新slots缓存信息。
	             但是MOVED重定向说明键对应的槽已经明确指定到新的节点，因此需要更新slots缓存信息。
               
               2.通常在集群模式下每次command执行客户端连接的节点是不一定的，每次操作会随机获取活跃节点连接，首先该节点会判断command是不是可以执行的命令，如可以执行客户端
                 会先计算key对应的slot，再根据slot找出对应的node，如果是当前node就会直接执行command，如果不是会给client返回MOVED重定向错误，通知其请求正确的节点(实际上这是
		         两次的客户端请求)，它的弊端是很明显的。 所以目前绝大数的Redis客户端都采用Smart客户端，Smart客户端通过在内部维护slot→node的映射关系，本地就可实现键到节点的查找，
		         从而保证IO效率的最大化，而MOVED重定向负责协助Smart客户端更新slot→node映射。
  
  4. redis 慢查询(slowlog)
     Redis配置项： slowlog-log-slower-than 预设阈值，命令执行时间超过阈值的才会被记录（单位：微秒us）。
                   slowlog-max-len 慢查询日志最大存储长度，当队列满了以后会以FIFO的方式出队列。
     
     动态设置redis参数并持久化到本地：  
	      config set slowlog-log-slower-than 默认10ms
	      config set slowlog-max-len  默认128
	      config rewrite （配置文件持久化）
	      
     相关命令：
          1.获取满查询日志：slowlog get [n]
	        日志的四个组成
		    1) (integer) 81015              慢查询日志的标识id
	            2) (integer) 1519709146         发生时间戳
	            3) (integer) 18269              命令耗时（不包括命令排队和网络传输时间）
	            4) 1) "DEL"                     执行命令和参数
	               2) "detail:redisJob-manufactory"

          2.获取慢查询日志列表当前的长度：slowlog len
	      3.慢查询日志重置（实际是对列表做清理操作）：slowlog reset

  5.pipeline机制：
     1. redis客户端执行一条命令的过程(RTT过程)：1）发送命令 2）命令排队 3）命令执行 4）返回结果。
     2. pipeline机制能将一组Redis命令进行组装，通过一次RTT传输给Redis，再将这组Redis命令的执行结果按顺序返回给客户端，
        因此pipeline不是原子的它执行n次命令，但是整个过程需要1次RTT过程。这样可以减少网络的开销，在网络环境不好的时候效果很明显。

        基于pipeline机制，可以对批量的hash，list，set操作进行优化。
  
  6.redis的事务机制和Lua
		   1 事务机制：
			  1.Redis提供了简单的事务功能，将一组需要一起执行的命令放到multi(开始)和exec(结束)两个命令之间，它们之间的命令是原子顺序执行的，
				如果要停止事务的执行，可以使用discard命令代替exec命令即可。但是它不支持事务中的回滚特性，同时无法实现命令之间的逻辑关系计算。

			  2.事务中错误的处理机制：
				1.命令错误：属于语法错误，会造成整个事务无法执行。
				  eg. 将set 写成 sett
				2.语法错误：其语法是正确的，因此之前的部分命令已经执行成功，开发人员需要自己修复这类问题。
				  eg. 误把sadd命令写成了zadd命令，zadd之前的命令都会正常执行成功

			  3.watch机制：某些应用场景需要在事务之前，确保事务中的key没有被其他客户端修改过，才执行事务，否则不执行（类似乐观锁）。
				在执行multi之前执行watch key的命令，如果事务中keybei别的客户端修改了，则事务执行失败。

		   2 Redis与Lua：
			  1.Lua是一种轻量级的脚本语言，它是由C语言实现的，作为嵌入式程序移植到其他应用程序。它提供了如下几种数据类型：booleans（布尔）、numbers（数值）、strings（字符串）、tables（表格）。
				扩展：学习Lua语言的语法和内置函数(http://www.lua.org/)。

			  2.Lua在Redis中的使用：
				执行Lua脚本有两种方法：eval和evalsha
				   1.1）eval ：
						1.执行命令 ： eval 脚本内容 key个数 key列表 参数列表
						如果lua脚本过长，可以用redis-cli --eval直接执行文件。
				   1.2）evalsha ：将Lua脚本加载到Redis服务端(内存中)，得到该脚本的SHA1校验和，evalsha命令使用SHA1作为参数可以直接执行对应Lua脚本，这样既可以避免每次发送lua脚本的开销
								  也可以是脚本功能得到服用。
						  1.script load ：加载脚本到redis中。
							script load "$(cat XXX.lua)"
										返回SHA1值 7413dc2440db1fea7c0a0bde841fa68eefaf149c

						  2.执行命令：evalsha 脚本SHA1值 key个数 key列表 参数列表


				Lua的内置Redis API：
				   2.1）redis.call
						redis.call("set", "hello", "world")
						redis.call("get", "hello")
						执行效果：eval 'return redis.call("get", KEYS[1])' 1 hello

				  2.2）redis.pcall
						redis.call执行失败，那么脚本执行结束会直接返回错误，而redis.pcall会忽略错误继续执行脚本。

		3.为什么我们要用Lua脚本功能？
				 1.Lua脚本可以将多条命令一次性打包，有效地减少网络开销。
				 2.Lua脚本可以定制的符合自身业务需求命令，而且命令常驻redis内存可以复用。
				 3.Lua脚本在Redis中是原子执行的。

				但是如果Lua脚本比较耗时，甚至Lua脚本存在问题，那么此时Lua脚本的执行会阻塞Redis，影响Redis的性能。

		4.Redis管理Lua脚本命令
				  1.script load "$(cat XXX.lua)" 加载Lua脚本到Redis内存中
				  2.script exists sha1           判断sha1是否已经加载到Redis内存中
				  3.script flush	         清除Redis内存已经加载的所有Lua脚本
				  4.script kill                  杀掉正在执行的Lua脚本



  7.redis阻塞问题：
      产生阻塞的一般原因：
         内在原因：
	         1.API或者数据结构使用不合理：慢查询和bigkeys
				   1.把高时间复杂度的命令修改为低复杂度的，如hgetall --> hmget ,尽量不在产线环境使用keys，sort的危险命令
				   2.把大对象数据缩减成小对象数据，避免一次命令操作操作太多数据。（将一个大对象的数据尽量视业务需求拆分成多个小对象数据，客户端可以通过一次查询操作执行多条命令（pipeline）
				   3. 来一次性获取所有数据，这样既可以减少客户端的网络IO消耗，也可以避免服务端bigkeys引起的慢查询）。
				   4.如何发现大对象？使用redis-cli --bigkeys命令
		 
			 2.cpu饱和：单线程的Redis处理命令时只能使用一个CPU，而CPU饱和是指Redis把单核CPU使用率跑到接近100%。
				   1.使用top命令识别cpu使用率高的REDIS进程。
				   2.使用统计命令redis-cli -h {ip} -p {port} --stat命令获取当前Redis使用情况
					 通过分析其它每秒平均处理的请求数目判断当前redis实例是否接近饱和（6w+左右接近饱和）。这种情况下只能通过水平扩展集群规模来分摊OPS压力。
				   3.只有几百或几千OPS的Redis实例就接近CPU饱和，有可能使用了高算法复杂度的命令。使用info commandstats来分析出redis命令不合理开销时间。

			 3.持久化阻塞：开启了持久化功能的Redis节点，持久化引起主线程阻塞的操作主要有fork阻塞、AOF刷盘阻塞、HugePage写操作阻塞。
		 
	     外在原因：
	        1.cpu资源竞争：redis是典型的cpu密集型应用，不推荐和其他多核cpu密集型服务部署在一起。别的服务在过度消耗cpu的情况下会严重影响redis吞吐量。
		
			2.内存交换(swap): 交换分区主要是在内存不够用的时候，将部分内存上的数据交换到swap空间上，以便让系统不会因内存不够用而导致oom或者更致命的情况出现。
			  如何识别redis内存交换:
				1.查询redis进程号：redis-cli -h {ip} -p {port} info server | grep process_id
						2.根据进程号查询redis内存交互信息：cat /proc/{process_id}/smaps | grep Swap
						  如果交换量都是0kb或者个别4kb，说明redis进程内存没有被交换。

			    预防swap：1.保证机器可用内存充足 2.确保所有redis实例都设置最大可用内存(maxmemory)

			3.网络问题：
			  1.连接拒绝
				 网络闪断。
				 Redis连接拒绝：当redis的的连接数大于maxcilents（默认10000）时，会拒绝新的连接连入。info stats | grep rejected_connections可以统计被拒绝的连接数目。
				 Redis链接溢出：进程限制 && Tcp backlog队列溢出
			  2.网络延迟：使用ping查看不同服务器之间的网络延迟数
			  3.网卡软中断

            Tips：定制redis日志，如加入日志监控，记录阻塞redis的ipport可以帮助我们快速定位问题，同时可以对redis部署的机器做全面监控。
      
  8.理解Redis内存：
    1.内存消耗
      1.1 内存使用统计：info memory
          used_memory:  Redis分配器分配的内存总量，也就是内部存储所有的数据内存占用率。
          used_memory_rss: 从操作系统系统角度看Redis进程所占用的物理内存总量。
	      used_memory_peak：内存使用的最大值，表示used_memory的峰值。
	   	  mem_fragmentation_ratio = used_memory_rss/used_memory ：
				 当 mem_fragmentation_ratio > 1,多出的部分内存并没有用于数据存储，而是被内存碎片所消耗，如果两者相差很大，说明碎片率严重。
			     当 mem_fragmentation_ratio < 1,一般出现在操作系统把Redis内存交换（Swap）到硬盘导致,这种情况下由于硬盘速度远远慢于内存，Redis性能会变得很差，甚至僵死。
  
      1.2 内存消耗划分：一个Redis进程内消耗主要包括自身内存+对象内存+缓冲内存+内存碎片，其中Redis空进程自身内存消耗非常少可以忽略不计。
          1.2.1：对象内存
	         对象内存是Redis内存占用最大的一块，存储着用户所有的数据。Redis所有的数据都采用key-value数据类型，对象内存消耗可以简单理解为sizeof（keys）+sizeof（values）。
		 
          1.2.2：缓冲内存
	         1)客户端缓冲：所有接入到Redis服务器TCP连接的输入输出缓冲。输入缓冲无法控制，最大空间为1G，如果超过将断开连接。
		               输出缓冲通过参数client-output-buffer-limit控制，默认值如下：
			       普通客户端：client-output-buffer-limit normal 0 0 0  缓冲区不做限制
                               从客户端：client-output-buffer-limit slave 256mb 64mb 60 缓冲区的大小大于256mb之后就会断开连接 || 缓冲区的大小大于64mb且超过了60s断开连接
                               发布订阅客户端：client-output-buffer-limit pubsub 32mb 8mb 60 缓冲区的大小大于32mb之后就会断开连接 || 缓冲区的大小大于8mb且超过了60s断开连接
			       
	         2)复制积压缓冲区：2.8版本以后提供可重用的固定大小缓冲区用于实现部分复制功能，repl-backlog-size参数控制，默认参数1MB
		 
		     3)AOF缓冲区：用于在Redis重写期间保存最近的写入命令。其消耗用户无法控制，取决于AOF重写时间和写入命令数，通常很小。
         
	       1.2.3：缓存碎片
			   1)内存碎片的产生：
				 1.Redis默认的内存分配器采用jemalloc，其分配内存策略一般采用固定范围的内存块进行分配。例如jemalloc在64位系统中将内存空间划分为：小、大、巨大三个范围
				   ・小：[8byte]，[16byte，32byte，48byte，...，128byte]，
				   ・大：[4KB，8KB，12KB，...，4072KB]
				   ・巨大：[4MB，8MB，12MB，...]
				   对于一个5k的对象，jemalloc可能会通常都是分配一个8k的内存块去保存，而不是几个不连续的内存块，因此剩下的3k空间就变成的内存碎片无法再使用。

				 2.频繁做更新操作（如append字符串追加，setrange从指定的offset处开始覆盖value的长度的操作），频繁的append操作会使数据大小超过预先分配的内存大小，
				   此时jemalloc就会分配新的内存块，之前的内存空间被释放产生内存碎片。


				 3.大量过期键删除后，删除的空间无法充分利用。例如有一批不连续且内存对象大小约为6kb的数据过期产生了大量的不连续内存空间，之后再保存的数据的如果大部分都
				   大于6kb的话，这些空间就很难被继续利用。因此这个场景下数据对齐就显得十分重要。

				 4.redis在rdb时也会可能导致碎片率升高：rdb机制使用了copy-on-write，在很高的update负载下，redis需要更多的内存才能完成rdb。

			   2)常见解决高内存碎片的方式：

				 通常：mem_fragmentation_ratio > 1 时表示存在内存碎片，值越大内存碎片率越高，jemalloc在没有任何碎片时碎片率约在1.03左右。

				 1.数据对齐：数据尽量采用数字类型或者固定长度字符串等存储，有助于内存释放以后继续有效利用。
				 2.安全重启：重启节点可以做到内存碎片重新整理，可以将碎片率过高的主节点转换为从节点，进行安全重启。

        1.3 子进程消耗：主要指执行AOF/RDB重写时Redis创建的子进程内存消耗。Redis执行fork操作产生的子进程内存占用量对外表现为与父进程相同，理论上需要一倍的物理内存来完成重写操作。
	   
            
     2.内存管理：
       2.1 设置内存上限 ：使用maxmemory参数限制最大可用内存。防止使用内存超过服务器物理内存，当超出内存上限maxmemory时使用LRU等删除策略释放空间。
       
       2.2 动态调整内存上限 ：config set maxmemory 10GB
       
       2.3 内存回收策略：
           1)到达过期时间的键对象删除 
	          惰性删除：客户端读取超时的键时会执行删除操作并返回空。这种策略可以节省CPU成本，不需要单独维护TTL链表来处理过期键的删除。单独使用这种策略存在过期的键一直没被访问无法删除
	                   内存空间得不到释放。（我们的冷门item就会出现这样的场景）
	     
	           定时任务删除：Redis内部维护一个定时任务，默认每秒运行10次（通过配置hz控制）。删除过期键逻辑采用了自适应算法，根据键的过期比例、使用快慢两种速率模式回收键。
	     
	   2)内存使用达到maxmemory上限时触发内存溢出控制策略 config get maxmemory-policy
	     maxmemory-policy配置（6种）
	           1.noeviction：默认策略不会删除任何数据，拒绝所有写入操作并返回客户端错误信息（error）OOM command not allowed when used memory，此时Redis只响应读操作。
	           2.volatile-lru：根据LRU算法删除设置了超时属性（expire）的键，直到腾出足够空间为止。如果没有可删除的键对象，回退到noeviction策略。
               3.allkeys-lru：根据LRU算法删除键，不管数据有没有设置超时属性，直到腾出足够空间为止。
               4.allkeys-random：随机删除所有键，直到腾出足够空间为止。
               5.volatile-random：随机删除过期键，直到腾出足够空间为止。
               6.volatile-ttl：根据键值对象的ttl属性，删除最近将要过期数据。如果没有，回退到noeviction策略。
	       
      3.内存优化
        3.1 理解readObject对象：redis存储的数据都使用redisObject来封装，包括string、hash、list、set、zset在内的所有数据类型。
	        readObject字段说明；
	              type ：当前对象使用的数据类型 （redis type命令5中返回值：string、hash、list、set、zset）
	              encoding ：key在redis内部存储的编码类型 （redis会根据key的情况动态调整编码类型）
				  lru  ：记录对象最后一次被访问的时间 （用于辅助LRU算法删除键数据。）
				  refcount ：记录当前对象被引用的次数，当refcount=0时，可以安全回收当前对象空间（object refcount{key}获取当前对象引用。）
				  *ptr ：与对象的数据内容相关，如果是整数，直接存储数据；否则表示指向数据的指针。
   
        3.2优化手段
			1.缩减键值对象：最直接的方式
			  key长度：如在设计键时，在完整描述业务情况下，键值越短越好
			  value长度：序列化以后再存储

			2.共享对象池：
			  共享对象池是指Redis内部维护[0-9999]的整数对象池。10000以内的整数类型redisObject对象都会共用共享对象池中的对象，利于节省空间。
			  经测试，使用共享对象池后，相同的数据内存使用降低30%以上。

			  2.1 为什么开启maxmemory和LRU淘汰策略后对象池无效？
				  每个对象最后访问时间存储在redisObject对象的lru字段。对象共享意味着多个引用共享同一个redisObject，这时lru字段也会被共享，导致无法获取每个对象的最后访问时间。

			  2.2 为什么只有整数对象池？
					  首先整数对象池复用的几率最大，其次对象共享的一个关键操作就是判断相等性，整数比较算法时间复杂度为O（1），只保留一万个整数为了防止对象池浪费。
	
			3.字符串优化
			  3.1 Redis字符串结构：简单动态字符串（simple dynamic string，SDS），有如下特点
								・ O(1)时间复杂度获取：字节数组(buf[])、已用长度(len)、未用长度(free)。
					・ 可用于保存字节数组，支持安全的二进制数据存储。
					・ 内部实现空间预分配机制，降低内存再分配次数。
					・ 惰性删除机制，字符串缩减后的空间不释放，作为预分配空间保留。

			  3.2 预分配机制： 会带来一定的内存浪费，尽量减少字符串频繁修改操作如append、setrange，改为直接使用set修改字符串，降低带来的内存浪费和内存碎片化。

			  3.3 字符串重构： 指不一定把每份数据作为字符串整体存储，像json这样的数据可以使用hash结构，既节省内存同时可以使用hmget、hmset命令支持字段的部分读取修改，而不用每次整体存取。

			4 编码优化：了解Redis内部string、list、hash、set、zet等存储数据的内部编码，所谓编码就是具体使用哪种底层数据结构来实现，编码不同将直接影响数据的内存占用和读写效率。

					object encoding{key} 命令可以获取编码类型。具体的type与encoding对应关系见第一节 1.redis 数据结构和内部编码。Redis作者想通过不同编码实现效率和空间的平衡，编码类型转换在Redis写入数据时自动完成，这个转换过程是不可逆的，转换规则只能从小内存编码向大内存编码转换。

					 hash类型一个优化实例：
					 一个hash类型的数据，其中有一个属性的长度为70个字节。在使用默认配置的hash类型存储时内存消耗会比较高，因为默认配置下hash-max-ziplistvalue默认值是64，
					 超过这个长度Redis会采用hashtable编码方式，hashtable消耗了大量内存（但是查询效率会提高），因此我们可以修改hash-max-ziplistvalue = 72来调整该hash类型
					 内部存储为ziplist，这调整可以节省很大一部分的内存空间。

					 tips：之前在redis阻塞一章某个案例提到，hset命令算法复杂度只有O（1）但某些Redis实例平均耗时却达到135微秒，十分不合理正常情况耗时应该在10微秒以下。
						   原因是该Redis实例为了追求低内存使用量，过度放宽ziplist使用条件（修改了hash-max-ziplist-entries和hash-max-ziplist-value配置）。
						   进程内的hash对象平均存储着上万个元素，而针对ziplist的操作算法复杂度在O（n）到O（n2）之间，操作变得更慢且更消耗CPU容易造成cpu饱和，
								   这对redis来说十分危险，因此一切优化都要结合自身情况来。

			5 控制键的数目：在客户端预估键规模，把大量键分组映射到多个hash结构中降低键的数量。
       	     
	 
   9.集群（RedisCluster）
      9.1 数据分布：
        1)数据分布理论：分布式数据库首先要解决把整个数据集按照分区规则映射到多个节点的问题，把数据集划分到多个节点上，每个节点负责整体数据的一个子集。
	                常见的分区规则有哈希分区和顺序分区两种。
			
	    2)常见的哈希分区规则:
           1. 节点取余分区  hash（key）% N 计算出哈希值，用来决定数据映射到哪一个节点上，这种方式优点是简单，但是当节点数量变化时，数据节点映射关系全部需要重新计算，
	                       会导致数据的重新迁移。

           2. 一致性哈希分区 为系统中每个节点分配一个token，范围一般在0~232，这些token构成一个哈希环。数据读写执行节点查找操作时，先根据key计算hash值，然后顺时针找到第一个大于
                             等于该哈希值的token节点。
	  
		   3. 虚拟槽分区
				 Slot(槽)：分散度良好的哈希函数把所有数据映射到一个固定范围的整数集合中，整数定义为槽（slot）。
			  Redis数据分区：Redis Cluser采用虚拟槽分区，所有的键根据哈希函数映射到0~16383整数槽内。
				计算公式：slot=CRC16（key）&16383。每一个节点负责维护一部分槽以及槽所映射的键值数，因此每次节点扩容时，只要把一部分的slot映射到新的节点上即可。

			  Redis虚拟槽分区的特点：
				 1.解耦数据和节点之间的关系，简化的扩容的难度
				 2.节点自身维护slot的映射关系，无需客户端或者代理服务器维护slot分区元数据
				 3.支持节点、槽、键之间的映射查询，适用于数据路由、在线伸缩等场景。
	     
	   
        3)redis cluster 功能限制
          1.key批量操作支持有限，目前只支持string的批量操作（mget，mset），list，hash等不支持批量操作。
		  2.key事务操作支持有限，多key在同一节点上的事务操做，分布在不同节点不支持。
		  3.key是数据分区的最小粒度，不能将一个大的键值对象如hash、list等映射到不同的节点。
		  4.不支持多数据库空间，集群模式下只能使用一个数据库空间，即db0。
		  5.复制结构只支持一层，从节点只能复制主节点，不支持嵌套树状复制结构。
	  
	
      9.2 集群搭建：
          1)节点准备 
	        修改所有节点的配置文件，并启动节点： ./redis-server conf/redis-6379.conf
          2)节点握手
	        所有节点在集群模式下的节点通过Gossip协议彼此通信，达到感知对方的过程： cluster meet {ip} {port}，
          3)分配slot 
                Redis集群把所有的数据映射到16384个槽中 ：redis-cli -h 127.0.0.1 -p 6379 cluster addslots {0...5461}
 
          4)使用redis-trib.rb搭建集群
			 1.redis-trib.rb是采用Ruby实现的Redis集群管理工具，使用之前需要安装Ruby依赖环境。
			 2.节点准备
			 3.创建集群
			   redis-trib.rb create --replicas 1 127.0.0.1:6481 127.0.0.1:6482 127.0.0.1:6483127.0.0.1:6484 127.0.0.1:6485 127.0.0.1:6486
			   --replicas参数指定集群中每个主节点配备几个从节点

       9.3 节点通信
           Redis集群采用P2P的Gossip（流言）协议，Gossip协议工作原理就是节点彼此不断通信交换信息，一段时间后所有的节点都会知道集群完整的信息，这种方式类似流言传播。
           1)通信流程
	          1.集群中的每个节点都会单独开辟一个TCP通道，用于节点之间彼此通信，通信端口号在基础端口上加10000。
              2.每个节点在固定周期内通过特定规则选择几个节点发送ping消息。
              3.接收到ping消息的节点用pong消息作为响应
	    
	     
	   2) Gossip消息
	      常用的Gossip消息可分为：
		    ping消息 : 用于检测节点是否在线和交换彼此状态信
	        pong消息 : 当接收到ping、meet消息时，作为响应消息回复给发送方确认消息正常通信。
	        meet消息 : 用于通知新节点加入.
	        fail消息 : 当节点判定集群内另一个节点下线时，会向集群内广播一个fail消息，其他节点接收到fail消息之后把对应节点更新为下线状态。
        
	
       9.4 集群伸缩
           原理：slot槽和对应数据在可以不同节点之间灵活移动。集群缩容只要先把相应master节点上的solt迁移走，然后关闭节点即可。集群扩容就是把新加入的节点
	            分配相应的slot槽即可。
  
       9.5 故障转移和集群运维
           1.什么事故障转移？
	         整个集群中某个master节点故障以后会自动进行master选举，让它其中的一个slave成为master，以保证集群的完整性。当某个master以及它的所以slave
	         都故障了，那此时整个集群就会处于不可用状态了。
	     
	   2.集群运维
	     1)验证集群完整性：默认情况下当集群16384个槽任何一个没有指派到节点时整个集群不可用。执行任何键命令返回（error）CLUSTERDOWNHash slot not served错误。
	     2)带宽消耗：集群内Gossip消息通信本身会消耗带宽，官方建议集群最大规模在1000以内。
	     3)集群倾斜：集群倾斜指不同节点之间数据量和请求量出现明显差异，这种情况将加大负载均衡和开发运维的难度
	                 1.数据倾斜	
						  1.节点和槽分配严重不均
						  2.不同槽对应键数量差异过大。键通过CRC16哈希函数映射到槽上，正常情况下槽内键数量会相对均匀。但当大量使用hash_tag时，会产生不同的键映射到同一个槽的情况。
						  3.集合对象包含大量元素。对于大集合对象的识别可以使用redis-cli--bigkeys命令识别
						  4.内存相关配置不一致。内存相关配置指hash-max-ziplist-value、setmaintset-entries等压缩数据结构配置。当集群大量使用hash、set等数据结构时也会造成数据倾斜。
  
                         2.请求倾斜：
			               集群内特定节点请求量/流量过大将导致节点之间负载不均。一般都是hotkey对应大对象操做如hgetall smembres等引起的。
				           所以一般不建议使用热键作为hash_tag，同时合理设计键，热点大集合对象做拆分或使用hmget替代hgetall避免整体读取。
			   
             4)集群读写分离 ：slave节点不接受任何读写请求，发送过来的key命令会重定向到负责slot的主节点上。
	     5)手动故障转移：指定slave节点发起转移流程，master从节点角色进行切换，slave节点变为新的master节点对外提供服务，旧的master节点变为它的slave节点。
  
  
  
  10.持久化策略：Redis支持RDB和AOF两种持久化机制，持久化功能有效地避免因进程退出造成的数据丢失问题，当下次重启时利用之前持久化的文件即可实现数据恢复。
  
      10.1 RDB ：把当前进程数据生成快照保存到硬盘的过程，触发RDB持久化过程分为手动触发和自动触发。
                 手动触发：
		   save ：阻塞当前Redis服务器，直到RDB过程完成为止。对于内存比较大的实例会造成长时间阻塞，线上环境不建议使用（该命令目前已经被废弃）。
		   bgsave ：Redis进程执行fork操作创建子进程，RDB持久化过程由子进程负责，完成后自动结束。阻塞只发生在fork阶段，一般时间很短。
  
                 自动触发场景：
		          1. save m n 表示m秒内数据集存在n次修改时，自动触发bgsave。在redis.conf中配置save选项，配置save:""可以禁用该功能。
                          2. slave节点执行全量赋值操作，master会自动生成rdb文件并发送给slave。
			  3. 执行debug reload命令重新加载Redis时，也会自动触发save操作
                          4. 默认情况下执行shutdown命令时，如果没有开启AOF持久化功能则自动执行bgsave。
  
                 rdb文件的处理：
		         保存：RDB文件保存在dir配置指定的目录下，文件名通过dbfilename配置指定，使用LZF算法对生成的RDB文件做压缩处理，压缩后的文件远远小于内存大小。
                               虽然压缩RDB会消耗CPU，但可大幅降低文件的体积，方便保存到硬盘或通过网络发送给从节点，因此线上建议开启。
  
                 rdb的优缺点：
		    优点：RDB是一个紧凑压缩的二进制文件，代表Redis在某个时间点上的数据快照。非常适用于容灾备份，全量复制等场景。而且他的恢复速度远大于AOF。
		    缺点：RDB方式数据没办法做到实时持久化/秒级持久化。因为bgsave每次运行都要执行fork操作创建子进程，属于重量级操作，频繁执行成本过高，同时会影响redis性能。
                          RDB文件使用特定二进制格式保存，老版本无法兼容新版本。
			 
			 
			 
      10.2 AOF（append only file）：以独立日志的方式记录每次写命令，重启时再重新执行AOF文件中的命令达到恢复数据的目的。
                                    AOF的主要作用是解决了数据持久化的实时性。
				    
		1.使用AOF
		   开启AOF功能需要设置配置：appendonly yes，默认不开启。AOF文件名
                   aof文件名称配置设置：    appendfilename，默认文件名是appendonly.aof

                2.AOF工作流程：
					  1）所有的写入命令会追加到aof_buf（缓冲区）中。
						   1.缓冲区中写入的直接是文本协议格式，因为文本协议有和好的兼容性，同时也避免了二次处理的开销。
						   2.Redis使用单线程响应命令，如果每次写AOF文件命令都直接追加到硬盘，那么性能完全取决于当前硬盘负载。

					  2）AOF缓冲区根据对应的策略向硬盘做同步操作。
						   1.AOF缓冲区同步文件策略，由参数appendfsync控制。可以配置的值有：always（每次命令写入aof_buf就同步一次），everysec（后台线程1s同步一次），no（同步操作完全由OS负责，一般30s）
							 出于性能的考虑一般配置为no。

					  3）随着AOF文件越来越大，需要定期对AOF文件进行重写，达到压缩的目的。
						   1.为甚要重写aof文件？AOF重写降低了文件占用空间，除此之外，另一个目的是：更小的AOF文件可以更快地被Redis加载。
						   2.AOF重写过程可以手动触发和自动触发：
							 手动触发：bgrewriteaof 命令
							 自动触发：
								   auto-aof-rewrite-min-size：表示运行AOF重写时文件最小体积，默认为64MB。
								   uto-aof-rewrite-percentage：代表当前AOF文件空间（aof_current_size）和上一次重写后AOF文件空间（aof_base_size）的比值。

								   触发时机：aof_current_size > auto-aof-rewrite-minsize &&（aof_current_size-aof_base_size）/aof_base_size >= auto-aof-rewritepercentage

					  4）当Redis服务器重启时，可以加载AOF文件进行数据恢复。
		        
      10.3 持久化带来问题的定位与优化 ：Redis持久化功能一直是影响Redis性能的高发地
      
           1.fork操作 ：当Redis做RDB或AOF重写时，一个必不可少的操作就是执行fork操作创建子进程，对于大多数操作系统来说fork是个重量级错。
	   
           2.子进程开销监控和优化 ：子进程负责AOF或者RDB文件的重写，它的运行过程主要涉及CPU、内存、硬盘三部分的消耗。

           3.AOF追加阻塞 ：当开启AOF持久化时，常用的同步硬盘的策略是everysec，用于平衡性能和数据安全性。对于这种方式，Redis使用另一条线程每秒执行fsync同步硬盘。当系统硬盘资源繁忙时，会造成Redis主线程阻塞。
       
			
  11.缓存设计 :缓存能够有效地加速应用的读写速度，同时也可以降低后端负载，合理的缓存设计可以让我们的redis集群更加的高效。
  
	  1): 缓存更新策略(参见itemservice增量系统) ： 缓存中的数据会和数据源中的真实数据有一段时间窗口的不一致，需要利用某些策略进行更新。
	                      一般我们会给cache的key设置值ttl，用于ttl到期将key过期删除。同时我们还要有一套主动更新的cache的流程，在真实数据更新后， 如何保证数据不丢失！）
	    
	  2): 缓存粒度控制 ：究竟是缓存全部属性还是只缓存部分重要属性呢？部分缓存和全部缓存各有各的优势，需要结合自身的业务需求去决定。
	                     全部缓存业务代码维护简单同时代码也更加的通用，但是它会占用更多的内存空间，序列化反序列化内存开销会比较大，网络流量也会比较大。

	  3): 缓存穿透优化： 缓存穿透是指查询一个根本不存在的数据，缓存层和存储层都不会命中。
	                     出现这种情况通常是两个原因：1.自身业务代码或者数据出现问题 2.一些恶意攻击、爬虫等造成大量空命中
			     关于缓存穿透，它会导致不存在的数据每次请求都要到存储层去查询，失去了缓存保护后端存储的意义。如果对这些空值也做了缓存，
                             意味着缓存层中存了更多的键，需要更多的内存空间（如果是恶意攻击，问题更严重）。
      			     
	                解决缓存穿透的两种方式：
			     1. 针对这类数据设置一个较短的过期时间，让其自动剔除。
			        String get(String key) {
					// 从缓存中获取数据
					String cacheValue = cache.get(key);
					// 缓存为空
					if (StringUtils.isBlank(cacheValue)) {
					// 从存储中获取
					String storageValue = storage.get(key);
					cache.set(key, storageValue);
					// 如果存储数据为空，需要设置一个过期时间(300秒)
					if (storageValue == null) {
					cache.expire(key, 60 * 5);
					}
					return storageValue;
					} else {
					// 缓存非空
					return cacheValue;
					}
			        }
	                  
			    2.布隆过滤器 ：在访问缓存层和存储层之前，将存在的key用布隆过滤器提前保存起来，做第一层拦截。
			                   这种方法适用于数据命中不高、数据相对固定、实时性低（通常是数据集较大）的应用场景，代码维护较为复杂，但是缓存空间占用少。
    
          4): 无底洞优化： 基于pipeline的网络优化
	          1.什么是无底洞现象？
		         无论是Memcache还是Redis这样的分布式系统，为了满足业务要求添加了大量新节点，但是发现性能不但没有好转反而下降了，这种现象称为缓存的“无底洞”现象。
	          2.出现的原因？   
				 键值数据库由于通常采用哈希函数将key映射到各个节点上，造成key的分布与业务无关，但是由于数据量和访问量的持续增长，造成需要添加大量节点做水平扩容，
				 导致键值分布到更多的节点上，批量操作通常需要从不同节点上获取，相比于单机批量操作只涉及一次网络操作，分布式批量操作会涉及多次网络时间。所以redis
				 官方建议一个redis的集群节点不要超过1000个。
		     
		  3.优化思路：在分布式条件下优化批量操作
			  1.并行IO：
				对于一个key我们可以计算出它所在的节点信息，这样就可以将属于同一个节点的key进行归档，得到每个节点的key子列表，之后对所有节点并行的执行mget
				或者Pipeline操作，这样网络次数虽然还是节点个数，但由于使用多线程网络时间变为O（1），这样既可以减少网络IO次数有可以提升客户端的整体响应。

			  2.hashtag
				hashtag可以将多个key强制分配到一个节点上，这样我们就可以使用一次网络IO批量获取数据。但是使用hashtag的业务维护的成本较高，同时很容易造成数据
				倾斜的问题。
			    
          5): 雪崩优化
	          什么是雪崩效应？ 如果缓存层由于某些原因不能提供服务，于是所有的请求都会达到存储层，存储层的调用量会暴增，造成存储层也会级联宕机的情况。对于有上下游服务的调用链也是如此。
                 1)保证缓存层服务高可用性。（Redis Cluster实现了高可用）
		         2)依赖隔离组件为后端限流并降级。 强烈推荐Hystrix组件 ：https://github.com/netflix/hystrix 除了原生以外，springcloud也提供了集成实现。
	
          6): 热点key重建优化
	          热点key问题：互斥锁、“永远不过期”能够在一定程度上解决热点key问题
		  
	  
  12.开发运维的陷阱
      1. flushall/flushdb误操作 
         借助AOF和RDB快速恢复数据 或者 禁用redis一些比较危险的命令如flushall/flushdb以及keys *等等
  
      2.处理bigkey ：bigkey是指key对应的value所占的内存空间比较大，一般分为字符串类型bigkey和非字符串类型bigkey。
                     字符串类型：体现在单个value值很大，一般认为超过10KB就是bigkey。非字符串类型：哈希、列表、集合、有序集合，体现在元素个数过多。
  
           bigkey的危害：1.造成节点内存使用不均匀 2.由于Redis单线程的特性，操作bigkey比较耗时，redis阻塞可能性较大 3.每次获取bigkey产生的网络流量较大，这对于千兆网卡的服务器来说简直是灭顶之灾。
  
           如何发现bigkey？
	        1.判断一个key是否为bigkey，只需要执行debug object key查看serializedlength属性即可。也可以从slowlog入手。
			2.主动检测：scan+debug object：如果怀疑存在bigkey，可以使用scan命令渐进的扫描出所有的key，分别计算每个key的serializedlength，找到对应bigkey进行相应的处理和报警，
						当然使用这种方式的前提不能因为scan对redis集群产生较大影响（建议scan操作在slave节点上执行）。

	  3.寻找热点key
		   热门商品通常会给系统带来巨大的流量，对存储这类信息的Redis来说却是一个巨大的挑战。以Redis Cluster为例，它会造成整体流量的不均衡，个别节点出现OPS过大的情况，节点连接数过多等问题。

		   1.在客户端设置全局字典（key和调用次数），这个非常简单也比较容易实现，为了防止存储的map过大记得定期清理即可。
			 它的问题也非常多：1.无法预知key的个数，存在内存泄露的危险。
							   2.对于客户端代码有侵入，各个语言的客户端都需要维护此逻辑，维护成本较高。
							   3.只能了解当前客户端的热点key，无法实现规模化运维统计。

			 tips ：客户端设置全局字典其实在redis service时更适合去实现。
        
  
           2.使用monitor命令统计热点key，Facebook开源的redis-faina正是利用上述原理使用Python语言实现的，。为了减少网络开销以及加快输出缓冲区的消费速度，monitor尽可能在本机执行。
  
           
	   3.可以通过对机器上所有Redis端口的TCP数据包进行抓取完成热点key的统计，此种方法对于Redis客户端和服务端来说毫无侵入，是比较完美的方案，但是依然存在两个问题：
	     1.需要一定的开发成本（可以利用一些开源方案如ELK来实现）。2.由于是以机器为单位进行统计，要想了解一个集群的热点key，需要进行后期汇总。
  
       tips ：总结出解决热点key问题的三种方案（前提是我们已经找到了所有的热点key了）；
               1.拆分复杂数据结构，减少多次访问带来的压力问题。
	       2.迁移热点key，以Redis Cluster为例，可以将热点key所在的slot单独迁移到一个新的Redis节点上，但此操作会增加运维成本。
	       3.JVM级别缓存加通知机制，可以将热点key放在业务端的本地缓存中，此种模式会造成各个业务端和Redis数据不一致，通常会使用发布订阅机制来解决类似问题。
  
     
  13.redis 优化方向：（内存优化，I/O优化，配置优化）
  
    1.简化键名和键值是最直观的减少内存占用的方式。  
    
    2.redis提供了流水线（Pipeline）功能，这样客户端能将一批命令一次性传到 Redis，减少了网络的开销。客户端和服务端网络延迟越大，pipeline效果越明显，
      这为性能优化提供了一个方向，可以结合自身业务减少网络IO次数。
    
      2.1 mget操作和pipeline的区别：mget操作是原子的，其批量操作只有一次网络I/O和一次命令执行。Pipeline不是原子的，它是把多个命令一次发送，所以只有一次网络I/O
          但是多个命令在redis服务端是顺序执行的，所以是多次的命令操作。
      
      2.2 redis mget ：keys集合对应的slot相同时支持mget操作
    
      2.3 lettuce 的 mget API命令原理? 根据key 计算solt落点。相同落点的key进行mget命令操作
      
      2.4 按node获取connection并行操作（pipeline操作）
      
          tip:不同key落在同一node的概率比落在同一个slot的概率大得多。目前测试按node获取connection效果比lettuce mget API要好。
      
    3.使用hash_tag优化（局限性大，只适合特定的业务场景）
         
    
    4.通过配置参数优化
   
   
拓展：
    redis出现问题的原因？
	    1.slowlog  
	    2.正在loading数据  
	    3.bigkey的问题  
	    4.rdb或者aof  
	    5.机器问题影响了redis  
	    6.redis连接数占满了  
	    7.内存碎片过多

	    
    redis4.x的新特性简介？
      1.加入了系统模块
        用户可以自己编写的代码来扩展和实现Redis本身并不具备的功能，它是通过高层次API实现的，它与Redis内核本身完全分离、互不干扰，所以用户可以在有需要的情况下才开启这个功能。
	    在redis.conf中开启的方式 ：# loadmodule /path/to/my_module.so
    
      2.缓存驱逐策略优化
        新增了 Last Frequently Used 缓存驱逐策略。LFU：最少的访问次数key驱逐。同时也对已有的缓存驱逐策略进行了优化， 使得它们能够更健壮、高效、快速和精确。
  
      3.PSYNC 2.0
        新版本的 PSYNC 命令解决了旧版本的 Redis 在复制时的一些不够优化的地方。旧版本中如果一个从服务器在 FAILOVER 之后成为了新的主节点，
	    那么其他从节点在复制这个新主的时候就必须进行全量复制。 Redis4.0以后，新主和从服务器在处理这种情况时，将在条件允许的情况下使用部分复制（lazy加载，在真正使用时复制对应的数据）。
	
      4.非阻塞 DEL FLUSHDB 和 FLUSHALL 命令
        UNLINK key：del 命令的异步版本，删除指定键的操作放在后台线程里面执行， 从而尽可能地避免服务器阻塞。
	    FLUSHDB ASYNC ，FLUSHALL ASYNC  带有这个选项的数据库删除操作将在后台线程进
       
      5.交换数据库
        SWAPDB 0 1 ， 我们可以将原来的数据库 0 变成数据库 1 ， 而原来的数据库 1 则变成数据库 0 。

      6.混合 RDB-AOF 持久化格式
        AOF 重写产生的文件将同时包含 RDB 格式的内容和 AOF 格式的内容， 其中 RDB 格式的内容用于记录已有的数据，而 AOF 格式的内存则用于记录最近发生了变化的数据，
	    这样 Redis 就可以同时兼有 RDB 持久化和 AOF 持久化的优点 ―― 既能够快速地生成重写文件，也能够在出现问题时，快速地载入数据。在redis.conf中通过aof-use-rdb-preamble选项开启。
	
      7.内存碎片整理
          1. 首先我们需要明确一个概念，redis的内存消耗不仅包含所有的key-value数据，还有描述这些key-value的元信息，以及许多管理功能的消耗，比如持久化、主从复制。
	          Redis4.0版本以后我们可以使用Redis Memeory Command详细分析内存使用情况，内存使用诊断，内存碎片回收。
	      
	      2. 在之前的redis版本中，遇到内存碎片的解决办法就是重启，尤其当它是master节点时还需要先将它降级成slave再重启。
	         4.0以后版本提供了优雅的解决方式
	         版本要求：1.Redis 4.0-RC3 以上版本 2.需要使用jemalloc作为内存分配器(默认的)
             功能介绍：
		        1. 支持在运行期进行自动内存碎片清理 (config set activedefrag yes)
	                2. 支持通过命令 memory purge 进行清理(与自动清理内存碎片区域不是同一块区域)
	   
          tips：Memory Command详解见：https://blog.csdn.net/n88Lpo/article/details/78466280

	
	
    安装redis4.0建议修改的配置项：
    
        maxmemory-policy : volatile-lru	   缓存驱逐策略（有ttl的key lru驱逐）。如果使用默认策略当内存满了以后只能提供读操作，写操做会报错。
	
	    slave-read-only : yes              开启slave只读模式，写操作只能通过master完成
	
	
        cluster-require-full-coverage:no   默认情况下当redis集群节点发现有至少一个hashslot未被covered时将会停止接收查询。这种情况下如果有一部份的集群down掉了，那整个集群将变得不可用。 
	                                   集群将会在所有的slot重新covered之后自动恢复可用。若想要设置集群在部份key space没有cover完成时继续去接收查询，就将参数设置为no。 

        maxclients:40000                   指定客户端的最大并发连接数，默认是没有限制，直到redis无法创建新的进程为止，设置该参数值为0也表示不限制。

        slowlog-log-slower-than:100000     慢查询日志记录，单位微秒，此处 100毫秒
        slowlog-max-len:1000               慢查询操作日志保留的最大条数，这两者有助于我们分析影响redis命令执行慢的操作类型

	    appendonly:no                      是否开启aof功能
        appendfsync:no                     aof中文件同步机制，aof功能关闭时该配置项不起作用
	
	    save:                              rdb功能配置，save:""可以禁用该功能。 该配置可以指定多长时间刷新快照至磁盘，这个选项有两个属性值，只有当两个属性值均满足时才会触发，可以设置多种级别，
	                                       格式：save <间隔时间（秒）> <写入次数> 例子 ： save 900 1   900秒内如果至少有1个key的值变化，则保存到磁盘

	    timeout:3600                       客户端空闲N秒后断开连接，参数0表示不启用，如果timeout设置很长会可能导致redis服务端的连接数过多，但一直保持着长链接可以复用客户端到服务端
	                                       tcp的channel，提升响应性能。
	                                   
        daemonize:no                       如果docker部署redis cluster要no
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
        